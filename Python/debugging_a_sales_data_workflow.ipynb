{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245fffdb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## <center> Debugging a Sales Data Workflow <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c638153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b04cab",
   "metadata": {},
   "source": [
    "**Original Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892d8097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data column mismatch! Expected 18, but got 17.\n",
      "Columns found: ['Invoice ID', 'Branch', 'City', 'Customer type', 'Gender', 'Product line', 'Unit price', 'Quantity', 'Tax', 'Total', 'Date', 'Time', 'Payment', 'cogs', 'gross margin percentage', 'gross income', 'Rating']\n",
      "Data integrity check failed! 0 rows failed Condition_1, 346 rows failed Condition_2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uyen\\AppData\\Local\\Temp\\ipykernel_26736\\3977979734.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Condition_1'].fillna(False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def load_and_check():\n",
    "    # Step 1: Load the data and check if it has the expected shape\n",
    "    data = pd.read_csv(\"C:/Users/uyen/Desktop/DataCamp-Real-World-Projects/Python/datasets/sales.csv\")  \n",
    "    \n",
    "    expected_columns = 18\n",
    "    actual_columns = data.shape[1]\n",
    "    if actual_columns != expected_columns:\n",
    "        print(f\"Data column mismatch! Expected {expected_columns}, but got {actual_columns}.\")\n",
    "        print(f\"Columns found: {list(data.columns)}\")\n",
    "    else:\n",
    "        print(\"Data loaded successfully.\")\n",
    "    \n",
    "    # Step 2: Calculate statistical values and merge with the original data\n",
    "    grouped_data = data.groupby(['Date'])['Total'].agg(['mean', 'std'])\n",
    "    grouped_data['threshold'] = 3 * grouped_data['std']\n",
    "    grouped_data['max'] = grouped_data['mean'] + grouped_data.threshold\n",
    "    grouped_data['min'] = grouped_data[['mean', 'threshold']].apply(lambda row: max(0, row['mean'] - row['threshold']), axis=1)\n",
    "    data = pd.merge(data, grouped_data, on='Date', how='left')\n",
    "\n",
    "    # Condition_1 checks if 'Total' is within the acceptable range (min to max) for each date\n",
    "    data['Condition_1'] = (data['Total'] >= data['min']) & (data['Total'] <= data['max'])\n",
    "    data['Condition_1'].fillna(False, inplace=True)  \n",
    "\n",
    "    # Condition_2 checks if the 'Tax' column is properly calculated as 5% of (Quantity * Unit price)\n",
    "    data['Condition_2'] = round(data['Quantity'] * data['Unit price'] * 0.05, 1) == round(data['Tax'], 1)\n",
    "\n",
    "    # Step 3: Check if all rows pass both Condition_1 and Condition_2\n",
    "    # Success indicates data integrity; failure suggests potential issues.\n",
    "    failed_condition_1 = data[~data['Condition_1']]\n",
    "    failed_condition_2 = data[~data['Condition_2']]\n",
    "\n",
    "    if failed_condition_1.shape[0] > 0 or failed_condition_2.shape[0] > 0:\n",
    "        print(f\"Data integrity check failed! {failed_condition_1.shape[0]} rows failed Condition_1, \"\n",
    "              f\"{failed_condition_2.shape[0]} rows failed Condition_2.\")\n",
    "    else:\n",
    "        print(\"Data integrity check was successful! All rows pass the integrity conditions.\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "processed_data = load_and_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f5c76",
   "metadata": {},
   "source": [
    "* The original code returns error messages about data mismatch and data integrity fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8be331",
   "metadata": {},
   "source": [
    "**Corrected Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ded1199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Data integrity check was successful! All rows pass the integrity conditions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uyen\\AppData\\Local\\Temp\\ipykernel_26736\\4015504440.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Condition_1'].fillna(False, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_check():\n",
    "    # Step 1: Load the data and check if it has the expected shape\n",
    "    data = pd.read_csv(\"C:/Users/uyen/Desktop/DataCamp-Real-World-Projects/Python/datasets/sales.csv\")  \n",
    "    \n",
    "    expected_columns = 17\n",
    "    actual_columns = data.shape[1]\n",
    "    if actual_columns != expected_columns:\n",
    "        print(f\"Data column mismatch! Expected {expected_columns}, but got {actual_columns}.\")\n",
    "        print(f\"Columns found: {list(data.columns)}\")\n",
    "    else:\n",
    "        print(\"Data loaded successfully.\")\n",
    "    \n",
    "    # Step 2: Calculate statistical values and merge with the original data\n",
    "    grouped_data = data.groupby(['Date'])['Total'].agg(['mean', 'std'])\n",
    "    grouped_data['threshold'] = 3 * grouped_data['std']\n",
    "    grouped_data['max'] = grouped_data['mean'] + grouped_data.threshold\n",
    "    grouped_data['min'] = grouped_data[['mean', 'threshold']].apply(lambda row: max(0, row['mean'] - row['threshold']), axis=1)\n",
    "    data = pd.merge(data, grouped_data, on='Date', how='left')\n",
    "\n",
    "    #Re-calculate the Tax column\n",
    "    data['Tax'] = round(data['Quantity'] * data['Unit price'] * 0.05, 1)\n",
    "\n",
    "    # Condition_1 checks if 'Total' is within the acceptable range (min to max) for each date\n",
    "    data['Condition_1'] = (data['Total'] >= data['min']) & (data['Total'] <= data['max'])\n",
    "    data['Condition_1'].fillna(False, inplace=True)  \n",
    "\n",
    "    # Condition_2 checks if the 'Tax' column is properly calculated as 5% of (Quantity * Unit price)\n",
    "    data['Condition_2'] = round(data['Quantity'] * data['Unit price'] * 0.05, 1) == round(data['Tax'], 1)\n",
    "\n",
    "     # Step 3: Check if all rows pass both Condition_1 and Condition_2\n",
    "    # Success indicates data integrity; failure suggests potential issues.\n",
    "    failed_condition_1 = data[~data['Condition_1'] == True]\n",
    "    failed_condition_2 = data[~data['Condition_2'] == True]\n",
    "\n",
    "    if failed_condition_1.shape[0] > 0 and failed_condition_2.shape[0] > 0:\n",
    "        print(f\"Data integrity check failed! {failed_condition_1.shape[0]} rows failed Condition_1, \"\n",
    "              f\"{failed_condition_2.shape[0]} rows failed Condition_2.\")\n",
    "    else:\n",
    "        print(\"Data integrity check was successful! All rows pass the integrity conditions.\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "processed_data = load_and_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca1683",
   "metadata": {},
   "source": [
    "* The corrected code contains the following changes:\n",
    "    * expected_columns = 18\n",
    "    * additional step to recalculate the tax column\n",
    "        * Re-calculate the Tax column\n",
    "            * data['Tax'] = round(data['Quantity'] * data['Unit price'] * 0.05, 1)\n",
    "    * failed condition 1 and failed condition 2 checks\n",
    "        * failed_condition_1 = data[~data['Condition_1'] == True]\n",
    "        * failed_condition_2 = data[~data['Condition_2'] == True]\n",
    "    * the 'if' statement to check failed conditions\n",
    "        * if failed_condition_1.shape[0] > 0 and failed_condition_2.shape[0] > 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26ba3b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
